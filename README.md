# Graph Reconstruction Attention Fusion Network for Multimodal Sentiment Analysis
This is a project about GRAFN
## Introduction
The development of social media has made Multimodal Sentiment Analysis (MSA) a hot research field. The MSA aims to analyze human emotions in videos using three modalities: vision, acoustics, and language. Most of the previous studies focus on the feature extraction of the data itself, ignoring the structural information between/within the multimodal data. The proposed GRAFN model effectively combines sequence features with structural information to improve the performance of MSA.
## Highlight
1.	An advanced MSA network is proposed to unit graph learning with sequence learning.
2.	A module based on the K-means is designed to reconstruct graph representations.
3.	An architecture is proposed to promote the text-guided multimodal fusion process.
4.	A structure is raised to adjust the sensitivity of features for downstream tasks.
## Conclusion
In this paper, we propose a graph reconstruction attention fusion network, which organically combines the sequence features and structural information of multimodal data, and significantly improves the performance of MSA. In the future, it would be interesting to integrate GRAFN model into mobile terminals to detect human emotions in short videos in real time.
